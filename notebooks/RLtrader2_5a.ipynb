{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qq0ThuG88Tl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb79afcf-2976-4e1b-8fd7-468a3540dc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hu4u1tTDM5SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07c3c14-ff7f-4780-bdd8-1b806f614f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.3.0\n",
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow===2.3.0\n",
            "  Using cached tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.47.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.14.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow===2.3.0) (0.3.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.4.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.2.0)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow===2.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qo_HsBuzZtLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b58b0c-8d69-4de9-d35e-6d17a82db5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WpBcCt5-SqCB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fe3d6b84-c926-4249-beae-8e11ec6a2a49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\\n!tar -xzvf ta-lib-0.4.0-src.tar.gz\\n%cd ta-lib\\n!./configure --prefix=/usr\\n!make\\n!make install\\n!pip install Ta-Lib\\n\\n!pip install technical\\n!pip install freqtrade'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "!tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
        "%cd ta-lib\n",
        "!./configure --prefix=/usr\n",
        "!make\n",
        "!make install\n",
        "!pip install Ta-Lib\n",
        "\n",
        "!pip install technical\n",
        "!pip install freqtrade'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V4lIIQgnic1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2a4730-1840-44cf-aab2-6e3f346eb45b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mplfinance in /usr/local/lib/python3.7/dist-packages (0.12.9b1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mplfinance) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mplfinance) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mplfinance) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mplfinance) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mplfinance) (2022.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.4.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.47.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: talib-binary in /usr/local/lib/python3.7/dist-packages (0.4.19)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from talib-binary) (1.18.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ta) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ta) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ta) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: binance_data in /usr/local/lib/python3.7/dist-packages (0.1.6)\n",
            "Requirement already satisfied: python-binance in /usr/local/lib/python3.7/dist-packages (from binance_data) (1.0.16)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.7/dist-packages (from python-binance->binance_data) (1.1.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.7/dist-packages (from python-binance->binance_data) (10.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-binance->binance_data) (1.15.0)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from python-binance->binance_data) (5.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from python-binance->binance_data) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from python-binance->binance_data) (2.23.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->python-binance->binance_data) (22.1.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->python-binance->binance_data) (2.10)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in /usr/local/lib/python3.7/dist-packages (from dateparser->python-binance->binance_data) (2022.3.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser->python-binance->binance_data) (2022.2.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser->python-binance->binance_data) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser->python-binance->binance_data) (2.8.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->python-binance->binance_data) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->python-binance->binance_data) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->python-binance->binance_data) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install unzip\n",
        "!pip install mplfinance\n",
        "!pip install keras\n",
        "!pip install keras-rl2\n",
        "#!pip install tensorflow\n",
        "!pip install talib-binary\n",
        "!pip install ta\n",
        "#!pip install technical\n",
        "!pip install binance_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f2P1Ff6TgoA5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "from statistics import mean, median, stdev\n",
        "import random\n",
        "from collections import deque\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from mplfinance.original_flavor import candlestick_ohlc\n",
        "import matplotlib.dates as mpl_dates\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from rl.agents import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, SoftmaxPolicy, EpsGreedyQPolicy, GreedyQPolicy, BoltzmannQPolicy, MaxBoltzmannQPolicy, BoltzmannGumbelQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "from google.colab import output\n",
        "\n",
        "from talib import RSI, ULTOSC, ADX, MINUS_DI, PLUS_DI, MFI, HT_TRENDLINE, MIDPOINT, BBANDS, MACD, AD, OBV, ADOSC, APO, AROONOSC, STOCHRSI, CMO, BOP, TRANGE, SAR, PPO, WILLR, ROC, MAMA, ATR\n",
        "import ta\n",
        "from binance_data import DataClient"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(ticker='BTCUSDT', interval='1h', futures=True, decimals=0, progress_statements=True,):\n",
        "  if futures:\n",
        "    directory='/data/binance_data_futures/'\n",
        "  else:\n",
        "    directory='/data/binance_data_spot/'\n",
        "\n",
        "  ### If inside colab notebook ###\n",
        "  if 'google.colab' in sys.modules:\n",
        "    !rm -rf /content/data\n",
        "    drive_path='/content/drive/MyDrive/RLtrader'+directory+interval+'_data/'+ticker\n",
        "    if not os.path.exists(drive_path):\n",
        "        os.makedirs(drive_path)\n",
        "        print(f'created dir {drive_path}')\n",
        "    else:\n",
        "      !rm -rf /content/dump\n",
        "      os.makedirs('/content/dump')\n",
        "      drive_dump=drive_path+'/old_concatenated_csvs'\n",
        "      try:\n",
        "        shutil.move(drive_dump, '/content/dump')\n",
        "        !rm -rf /content/dump\n",
        "      except FileNotFoundError:\n",
        "        None\n",
        "\n",
        "    local_dir = '/content'+directory+interval+'_data/'+ticker\n",
        "    shutil.move(drive_path, local_dir)\n",
        "\n",
        "    # refill with newer data \n",
        "    print('\\n updating data...')\n",
        "    store_data = DataClient(futures=futures).kline_data([ticker.upper()], interval, storage=['csv', os.getcwd()+directory], progress_statements=progress_statements)\n",
        "    local_dir_updated=os.getcwd()+directory+interval+'_data/'+ticker\n",
        "    shutil.move(local_dir_updated, drive_path)\n",
        "\n",
        "    tckr_df = pd.read_csv(drive_path+'/'+ticker+'.csv', header=0)\n",
        "    return tckr_df\n",
        "  else:\n",
        "    local_dir=os.getcwd()+directory+interval+'_data/'+ticker\n",
        "    if not os.path.exists(local_dir):\n",
        "        os.makedirs(local_dir)\n",
        "        print(f'created dir {local_dir}')\n",
        "    print('\\n updating data...')\n",
        "    store_data = DataClient(futures=futures).kline_data([ticker.upper()], interval, storage=['csv', os.getcwd()+directory], progress_statements=progress_statements)\n",
        "    local_dir_updated=os.getcwd()+directory+interval+'_data/'+ticker\n",
        "\n",
        "    tckr_df = pd.read_csv(local_dir_updated+'/'+ticker+'.csv', header=0)\n",
        "    return tckr_df"
      ],
      "metadata": {
        "id": "KTyzikd6GYBc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_df(seconds, dir, itv, tckr, futures):\n",
        "  try:\n",
        "    if 'google.colab' in sys.modules:\n",
        "      full_path='/content/drive/MyDrive/RLtrader'+dir+itv+'_data/'+tckr+'/'+tckr+'.csv'\n",
        "    else:\n",
        "      full_path=os.getcwd()+dir+itv+'_data/'+tckr+'/'+tckr+'.csv'\n",
        "    tckr_df = pd.read_csv(full_path)\n",
        "    #tckr_df['Opened'] = pd.to_datetime(tckr_df['Opened'])\n",
        "    timestamp_last = pd.to_datetime(tckr_df.iloc[-1]['Opened']).value // 10 ** 9\n",
        "    diff=time.time()-timestamp_last\n",
        "    print(f' avg gain/loss data is of by {diff} timestamps')\n",
        "    # checking how many seconds old the local df is\n",
        "    if diff>seconds:\n",
        "      raise FileNotFoundError(\"Out of date dataframe (1day)\")\n",
        "    return tckr_df\n",
        "  except FileNotFoundError:\n",
        "    return get_data(ticker=tckr, interval=itv, futures=futures)"
      ],
      "metadata": {
        "id": "Bu5mItgJKURT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_levels(ticker='BTCUSDT', interval='1m',  futures=True, decimals=0, current_price_offset=15,volume_above_avg=False):\n",
        "  ### get data ###\n",
        "  if futures:\n",
        "    directory='/data/binance_data_futures/'\n",
        "  else:\n",
        "    directory='/data/binance_data_spot/'\n",
        "  tckr_df = check_df(86400, directory, interval, ticker, futures)\n",
        "\n",
        "  ### searchin for lvls ###\n",
        "  vol_array=tckr_df['Volume'][1:].to_numpy()\n",
        "  avg_vol=np.mean(vol_array)\n",
        "  tckr_lvls={}\n",
        "  for open, close, volume, close_next in zip(tckr_df['Open'][:-1].to_numpy(), tckr_df['Close'][:-1].to_numpy(), vol_array, tckr_df['Close'][1:].to_numpy()):\n",
        "    #if (not volume_above_avg or volume>=avg_vol) and band_top>close>band_bottom:\n",
        "    if (close>open>close_next) or (close<open<close_next):\n",
        "      close=round(close, decimals)\n",
        "      if close in tckr_lvls:\n",
        "        tckr_lvls[close]+=1\n",
        "      else:\n",
        "        tckr_lvls[close]=1\n",
        "      if volume>=avg_vol:\n",
        "        tckr_lvls[close]+=1\n",
        "      #print(row)\n",
        "  tckr_lvls={k: v for k, v in sorted(tckr_lvls.items(), key=lambda item: item[1], reverse=True)}\n",
        "  #print(tckr_lvls)\n",
        "  return tckr_lvls"
      ],
      "metadata": {
        "id": "v5SEeQqNKSkk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yhXYeRVZJeaJ"
      },
      "outputs": [],
      "source": [
        "def get_avg_changes(ticker='BTCUSDT', interval='1m', futures=True):\n",
        "  ### get data ###\n",
        "  if futures:\n",
        "    directory='/data/binance_data_futures/'\n",
        "  else:\n",
        "    directory='/data/binance_data_spot/'\n",
        "  tckr_df = check_df(86400, directory, interval, ticker, futures)\n",
        "\n",
        "  open_array=tckr_df['Open'].to_numpy()\n",
        "  close_array=tckr_df['Close'].to_numpy()\n",
        "  #low_array=tckr_df['Low'].to_numpy()\n",
        "  #high_array=tckr_df['High'].to_numpy()\n",
        "  #vol_array=tckr_df['Volume'].to_numpy()\n",
        "\n",
        "  gain = [ (close/open-1)*100 for open, close in zip(open_array, close_array) if close>open]\n",
        "  loss = [ (open/close-1)*100 for open, close in zip(open_array, close_array) if close<open]\n",
        "  #HL_distance = [ (high/low-1)*100 for low, high in zip(low_array, high_array)]\n",
        "\n",
        "  #avg_vol=np.mean(vol_array)\n",
        "  #stdev_vol=np.std(vol_array)\n",
        "  #print(f'interval: {interval} avg_gain: {mean(gain)} stdev: {stdev(gain)} avg_loss: {mean(loss)} stdev: {stdev(loss)}')\n",
        "  #print(f'avg_volume: {avg_vol} stdev: {stdev_vol} avg_High_Low_distance: {mean(HL_distance)} stdev: {stdev(HL_distance)}')\n",
        "  return mean(gain),stdev(gain),mean(loss),stdev(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L-haqm_e0ZI7"
      },
      "outputs": [],
      "source": [
        "##### SIGNAL GENERATORS #####\n",
        "#############################\n",
        "def Hour_strat(hour_col):\n",
        "  h_dict={ 0:1, 1:-2, 2:-4, 3:-4, 4:-1, 5:1, 6:2, 7:1, 8:0, 9:-3, 10:-1, 11:1, 12:1,\n",
        "      13:3, 14:-3, 15:2, 16:1, 17:-1, 18:1, 19:3, 20:0, 21:4, 22:4, 23:-2 }\n",
        "  Hour_sig=[]\n",
        "  for i in range(len(hour_col)):\n",
        "    Hour_sig.append(h_dict[hour_col.iloc[i]])\n",
        "  return Hour_sig\n",
        "\n",
        "def Weekday_strat(column):\n",
        "  wd_dict={ 0:-1, 1:1, 2:0, 3:2, 4:-2, 5:1, 6:1 }\n",
        "  Weekday_sig=[]\n",
        "  for i in range(len(column)):\n",
        "    Weekday_sig.append(wd_dict[column.iloc[i]])\n",
        "  return Weekday_sig\n",
        "\n",
        "def ULT_RSI_strat(column):\n",
        "  signals=[0]\n",
        "  for i in range(1,len(column)):\n",
        "    # Overbought\n",
        "    if column.iloc[i-1]>65.0:\n",
        "      signals.append(-1)\n",
        "    # Oversold\n",
        "    elif column.iloc[i-1]<35.0:\n",
        "      signals.append(1)\n",
        "    # Sell singal\n",
        "    elif column.iloc[i-1]>65.0 and column.iloc[i]<65.0:\n",
        "      signals.append(-2)\n",
        "    # Buy singal\n",
        "    elif column.iloc[i-1]<35.0 and column.iloc[i]>35.0:\n",
        "      signals.append(2)\n",
        "    else:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def ADX_strat(adx_col,minus_DI,plus_DI):\n",
        "  signals=[0]\n",
        "  for i in range(1,len(adx_col)):\n",
        "    # Strong BUY signal\n",
        "    if plus_DI.iloc[i]>minus_DI.iloc[i] and plus_DI.iloc[i-1]<minus_DI.iloc[i-1] and adx_col.iloc[i]>25.0:\n",
        "      signals.append(4)\n",
        "    # BUY signal\n",
        "    elif plus_DI.iloc[i]>minus_DI.iloc[i] and plus_DI.iloc[i-1]<minus_DI.iloc[i-1] and adx_col.iloc[i]>20.0:\n",
        "      signals.append(3)\n",
        "\n",
        "    # Strong SELL signal\n",
        "    elif plus_DI.iloc[i]<minus_DI.iloc[i] and plus_DI.iloc[i-1]>minus_DI.iloc[i-1] and adx_col.iloc[i]>25.0:\n",
        "      signals.append(-4)\n",
        "    # SELL signal\n",
        "    elif plus_DI.iloc[i]<minus_DI.iloc[i] and plus_DI.iloc[i-1]>minus_DI.iloc[i-1] and adx_col.iloc[i]>20.0:\n",
        "      signals.append(-3)\n",
        "    \n",
        "    # strong heading toward BUY\n",
        "    elif plus_DI.iloc[i]>plus_DI.iloc[i-1] and minus_DI.iloc[i]<minus_DI.iloc[i-1] and plus_DI.iloc[i]<minus_DI.iloc[i] and adx_col.iloc[i]>25.0:\n",
        "      signals.append(2)\n",
        "    # strong heading toward SELL\n",
        "    elif plus_DI.iloc[i]<plus_DI.iloc[i-1] and minus_DI.iloc[i]>minus_DI.iloc[i-1] and plus_DI.iloc[i]>minus_DI.iloc[i] and adx_col.iloc[i]>25.0:\n",
        "      signals.append(-2)\n",
        "\n",
        "    # heading toward BUY\n",
        "    elif plus_DI.iloc[i]>plus_DI.iloc[i-1] and minus_DI.iloc[i]<minus_DI.iloc[i-1] and plus_DI.iloc[i]<minus_DI.iloc[i] and adx_col.iloc[i]>20.0:\n",
        "      signals.append(1)\n",
        "    # heading toward SELL\n",
        "    elif plus_DI.iloc[i]<plus_DI.iloc[i-1] and minus_DI.iloc[i]>minus_DI.iloc[i-1] and plus_DI.iloc[i]<minus_DI.iloc[i] and adx_col.iloc[i]>20.0:\n",
        "      signals.append(-1)\n",
        "    else:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def ADX_trend(column):\n",
        "  signals=[0]\n",
        "  for i in range(1,len(column)):\n",
        "    # Strong trend\n",
        "    if column.iloc[i]>25.0:\n",
        "      signals.append(1)\n",
        "    # Weak trend\n",
        "    elif column.iloc[i]<20.0:\n",
        "      signals.append(-1)\n",
        "    else:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def MFI_strat(mfi_col):\n",
        "  signals=[0]\n",
        "  for i in range(1,len(mfi_col)):\n",
        "    # Strong BUY signal\n",
        "    if mfi_col.iloc[i]>90:\n",
        "      signals.append(2)\n",
        "    # Strong SELL signal\n",
        "    elif mfi_col.iloc[i]<10:\n",
        "      signals.append(-2)\n",
        "    # BUY signal\n",
        "    elif mfi_col.iloc[i]>80:\n",
        "      signals.append(1)\n",
        "    # SELL signal\n",
        "    elif mfi_col.iloc[i]<20:\n",
        "      signals.append(-1)\n",
        "    else:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def MFI_divergence(mfi_col,close_col):\n",
        "  signals=[0]\n",
        "  for i in range(1,len(mfi_col)):\n",
        "    # BUY signal\n",
        "    if (mfi_col.iloc[i-1]<20 and mfi_col.iloc[i]>20) and (close_col.iloc[i]<close_col.iloc[i-1]):\n",
        "      signals.append(1)\n",
        "    # SELL signal\n",
        "    elif (mfi_col.iloc[i-1]>80 and mfi_col.iloc[i]<80) and (close_col.iloc[i]>close_col.iloc[i-1]):\n",
        "      signals.append(-1)\n",
        "    else:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def MACD_cross(macd_col,signal_col):\n",
        "  signals=[0]\n",
        "  for i in range(1,len(macd_col)):\n",
        "    # Buy signal\n",
        "    if macd_col.iloc[i]>signal_col.iloc[i] and macd_col.iloc[i-1]<signal_col.iloc[i-1]:\n",
        "      signals.append(1)\n",
        "    # Sell signal\n",
        "    elif macd_col.iloc[i]<signal_col.iloc[i] and macd_col.iloc[i-1]>signal_col.iloc[i-1]:\n",
        "      signals.append(-1)\n",
        "    else:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def MACDhist_reversal(macdhist_col):\n",
        "  signals=[0,0]\n",
        "  for i in range(2,len(macdhist_col)):\n",
        "    # Buy signal\n",
        "    if macdhist_col.iloc[i]>macdhist_col.iloc[i-1] and (macdhist_col.iloc[i-1]<macdhist_col.iloc[i-2]<macdhist_col.iloc[i-3]):\n",
        "      signals.append(1)\n",
        "    # Sell signal\n",
        "    elif macdhist_col.iloc[i]<macdhist_col.iloc[i-1] and (macdhist_col.iloc[i-1]>macdhist_col.iloc[i-2]>macdhist_col.iloc[i-3]):\n",
        "      signals.append(-1)\n",
        "    else:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def MACD_zerocross(macd_col,signal_col):\n",
        "  signals=[0]\n",
        "  for i in range(1,len(macd_col)):\n",
        "    # Buy signal\n",
        "    if macd_col.iloc[i]>0 and macd_col.iloc[i-1]<0:\n",
        "      signals.append(1)\n",
        "    # Buy signal\n",
        "    elif signal_col.iloc[i]>0 and signal_col.iloc[i-1]<0:\n",
        "      signals.append(1)\n",
        "    # Sell signal\n",
        "    elif macd_col.iloc[i]<0 and macd_col.iloc[i-1]>0:\n",
        "      signals.append(-1)\n",
        "    # Sell signal\n",
        "    elif signal_col.iloc[i]<0 and signal_col.iloc[i-1]>0:\n",
        "      signals.append(-1)\n",
        "    else:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def ATR_strat(atr_col):\n",
        "  signals=[0]\n",
        "  return signals\n",
        "\n",
        "def price_levels(close_col, interval='1m'):\n",
        "  signals=[]\n",
        "  lvls=get_levels(futures=True, interval=interval, decimals=0)\n",
        "  for i in range(0,len(close_col)):\n",
        "    try:\n",
        "      signals.append( lvls[round(close_col.iloc[i], 0)]  )\n",
        "    except:\n",
        "      signals.append(0)\n",
        "  return signals\n",
        "\n",
        "def move_prob(open_col_np, close_col_np, futures=True, interval='1m'):\n",
        "  avg_gain,gain_stdev,avg_loss,loss_stdev,*_=get_avg_changes(ticker='BTCUSDT', interval=interval, futures=futures)\n",
        "  signals=[ ((((close/open)-1)*100)-avg_gain)+((((close/open)-1)*100)/gain_stdev) if ((close/open)-1)>0 else ((((close/open)-1)*100)-avg_loss)+((((close/open)-1)*100)/loss_stdev) for open, close in zip(open_col_np,close_col_np) ]\n",
        "  return signals\n",
        "\n",
        "def vol_prob(vol_col_np):\n",
        "  avg_vol=np.mean(vol_col_np)\n",
        "  stdev_vol=np.std(vol_col_np)\n",
        "  signals=(vol_col_np-avg_vol)/stdev_vol\n",
        "  return signals\n",
        "\n",
        "def scaleColumns(df, scaler):\n",
        "    for col in df.columns:\n",
        "      if col not in ['Open time', 'Close time', 'Open', 'High', 'Low', 'Close']:\n",
        "        #print(col)\n",
        "        #caler.fit(df[[col]])\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HnFPjABxDApd"
      },
      "outputs": [],
      "source": [
        "def add_AT_features(df, suffix='_'):\n",
        "  print(f'     adding features to {suffix}...')\n",
        "  np_vol=df['Volume'].to_numpy()\n",
        "  np_open=df['Open'].to_numpy()\n",
        "  np_close=df['Close'].to_numpy()\n",
        "  np_high=df['High'].to_numpy()\n",
        "  np_low=df['Low'].to_numpy()\n",
        "  if suffix=='1m': \n",
        "    suffix=''\n",
        "    #df['weekday']=pd.to_datetime(df['Open time'], unit='ms').dt.dayofweek\n",
        "    #df['hour']=pd.to_datetime(df['Open time'], unit='ms').dt.hour\n",
        "    #df['hour_sig']=Hour_strat(df['hour'])\n",
        "    #df['weekday_sig']=Weekday_strat(df['weekday'])\n",
        "    #df.drop(columns=['weekday',\t'hour'],inplace=True)\n",
        "    df['lvls_count']=price_levels(df['Close'])\n",
        "    df['move_prob']=move_prob(np_open,np_close)\n",
        "    df['vol_prob']=vol_prob(np_vol)\n",
        "  else:\n",
        "    df['lvls_count'+suffix]=price_levels(df['Close'], interval=suffix)\n",
        "    df['move_prob'+suffix]=move_prob(np_open,np_close,interval=suffix)\n",
        "    df['vol_prob'+suffix]=vol_prob(np_vol)\n",
        "  open=df['Open'] \n",
        "  high=df['High']\n",
        "  low=df['Low']\n",
        "  close=df['Close']\n",
        "  volume=df['Volume']\n",
        "  #print(suffix)\n",
        "  #df=ta.add_all_ta_features(df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)\n",
        "  df['RSI'+suffix] =                                                   RSI(close, timeperiod=10)\n",
        "  df['ULT'+suffix] =                                                   ULTOSC(high, low, close, timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
        "  df['ADX'+suffix] =                                                   ADX(high, low, close, timeperiod=14)\n",
        "  df['-DI'+suffix] =                                                   MINUS_DI(high, low, close, timeperiod=14)\n",
        "  df['+DI'+suffix] =                                                   PLUS_DI(high, low, close, timeperiod=14)\n",
        "  df['MFI'+suffix] =                                                   MFI(high, low, close, volume, timeperiod=14)\n",
        "  #df['Hilbert'+suffix] =                                               HT_TRENDLINE(close)\n",
        "  #df['MIDPOINT'+suffix] =                                              MIDPOINT(close, timeperiod=14)\n",
        "  df['macd'+suffix],df['macdsignal'+suffix],df['macdhist'+suffix] =    MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
        "  #df['ATR'+suffix] =                                                   ATR(high, low, close, timeperiod=14)\n",
        "  df['ADOSC'+suffix] =                                                 ADOSC(high, low, close, volume, fastperiod=3, slowperiod=10)\n",
        "  df['APO'+suffix] =                                                   APO(close, fastperiod=12, slowperiod=26, matype=0)\n",
        "  df['AROONOSC'+suffix] =                                              AROONOSC(high, low, timeperiod=14)\n",
        "  df['STOCHRSIfastk'+suffix], df['STOCHRSIfastd'+suffix] =             STOCHRSI(close, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
        "  df['CMO'+suffix] =                                                   CMO(close, timeperiod=14)\n",
        "  df['BOP'+suffix] =                                                   BOP(open, high, low, close)\n",
        "  df['TRANGE'+suffix] =                                                TRANGE(high, low, close)\n",
        "  df['PPO'+suffix] =                                                   PPO(close, fastperiod=12, slowperiod=26, matype=0)\n",
        "  df['WILLR'+suffix] =                                                 WILLR(high, low, close, timeperiod=14)\n",
        "  df['KST'+suffix] =                                                  ta.trend.kst_sig(close)\n",
        "  df['Vortex'+suffix] =                                               ta.trend.VortexIndicator(high, low, close).vortex_indicator_diff()\n",
        "  df['STC'+suffix] =                                                  ta.trend.STCIndicator(close).stc()\n",
        "  df['PVO'+suffix] =                                                  ta.momentum.PercentageVolumeOscillator(volume).pvo()\n",
        "\n",
        "  df['AO'+suffix] =                                                   ta.momentum.AwesomeOscillatorIndicator(high, low).awesome_oscillator()\n",
        "  #df['ROC'+suffix] =                                                   ROC(close, timeperiod=10) #klon ceny\n",
        "  #df['OBV'+suffix] =                                                   OBV(close, volume) #klon ceny\n",
        "  #df['AD'+suffix] =                                                    AD(high, low, close, volume) #klon ceny\n",
        "  #df['mama'], df['fama'] = MAMA(close, fastlimit=0, slowlimit=0)\n",
        "  #df['SAR'+suffix] =                                                   SAR(high, low, acceleration=0, maximum=0)\n",
        "  #df['upperband'], df['middleband'], df['lowerband'] =                BBANDS(close, timeperiod=timeperiod_short, nbdevup=2, nbdevdn=2, matype=0) #klon ceny\n",
        "  #print(df.head())\n",
        "  df['RSI_sig'+suffix]=ULT_RSI_strat(df['RSI'+suffix])\n",
        "  df['ULT_sig'+suffix]=ULT_RSI_strat(df['ULT'+suffix])\n",
        "  df['ADX_sig'+suffix]=ADX_strat(df['ADX'+suffix], df['-DI'+suffix], df['+DI'+suffix])\n",
        "  df['ADX_trend'+suffix]=ADX_trend(df['ADX'+suffix])\n",
        "  df['MFI_strat'+suffix]=MFI_strat(df['MFI'+suffix])\n",
        "  df['MFI_divergence'+suffix]=MFI_divergence(df['MFI'+suffix], df['Close'])\n",
        "  df['MACD_cross'+suffix]=MACD_cross(df['macd'+suffix],df['macdsignal'+suffix])\n",
        "  df['MACDhist_reversal'+suffix]=MACDhist_reversal(df['macdhist'+suffix])\n",
        "  df['MACD_zerocross'+suffix]=MACD_zerocross(df['macd'+suffix],df['macdsignal'+suffix])\n",
        "\n",
        "  # OHLC simple features\n",
        "  df['C-O'+suffix]=np_close-np_open\n",
        "  df['H-L'+suffix]=np_high-np_low\n",
        "  # down candle wicks\n",
        "  df['H-O'+suffix]=np_high-np_open\n",
        "  df['C-L'+suffix]=np_open-np_low\n",
        "  # up candle wicks\n",
        "  df['O-L'+suffix]=np_open-np_low\n",
        "  df['H-C'+suffix]=np_high-np_close\n",
        "\n",
        "  df = df.drop(columns=['MFI'+suffix,])\n",
        "  #df = df.drop(columns=['RSI'+suffix, 'macd'+suffix, 'macdsignal'+suffix, 'macdhist'+suffix])\n",
        "  #df = df.drop(columns=['RSI'+suffix, 'ULT'+suffix, 'ADX'+suffix, '-DI'+suffix, '+DI'+suffix, 'MFI'+suffix, 'Hilbert'+suffix, 'MIDPOINT'+suffix, 'macd'+suffix, 'macdsignal'+suffix, 'macdhist'+suffix])\n",
        "  return scaleColumns(df, preprocessing.MinMaxScaler())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-p3kWnlxapt3"
      },
      "outputs": [],
      "source": [
        "def get_df(interval_list, month_list):\n",
        "  dfs=[]\n",
        "  for mth in month_list:\n",
        "    for itv in interval_list:\n",
        "      file_name='BTCUSDT-'+itv+'-2022-'+mth+'.zip'\n",
        "      link ='https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/'+itv+'/'+file_name\n",
        "      !wget -O $file_name $link\n",
        "      !unzip -o $file_name\n",
        "      if itv=='1m':\n",
        "        df=pd.read_csv(file_name)\n",
        "        df.columns = ['Open time',\t'Open',\t'High',\t'Low',\t'Close',\t'Volume',\t'Close time',\t'Quote asset volume',\t'Number of trades',\t'Taker buy base asset volume',\t'Taker buy quote asset volume',\t'Ignore']\n",
        "        df.drop(columns=['Quote asset volume',\t'Number of trades',\t'Taker buy base asset volume',\t'Taker buy quote asset volume',\t'Ignore'],inplace=True)\n",
        "        df=add_AT_features(df, itv)\n",
        "      else:\n",
        "        _df=pd.read_csv(file_name)\n",
        "        _df.columns = ['Open time',\t'Open',\t'High',\t'Low',\t'Close',\t'Volume',\t'Close time',\t'Quote asset volume',\t'Number of trades',\t'Taker buy base asset volume',\t'Taker buy quote asset volume',\t'Ignore']\n",
        "        _df.drop(columns=['Quote asset volume',\t'Number of trades',\t'Taker buy base asset volume',\t'Taker buy quote asset volume',\t'Ignore'],inplace=True)\n",
        "        _df=add_AT_features(_df, itv)\n",
        "        suff='_'+itv\n",
        "        df=pd.merge_asof(df,_df, on='Close time',suffixes=('', suff))\n",
        "        df.drop(columns=['Open time_'+itv,'Open_'+itv, 'High_'+itv, 'Low_'+itv, 'Close_'+itv, 'Volume_'+itv,],inplace=True)\n",
        "      #print(df[73:93])\n",
        "    dfs.append(df)\n",
        "  df=pd.concat(dfs, ignore_index=True)\n",
        "  df.fillna(method='ffill',inplace=True)\n",
        "  df.dropna(inplace=True)\n",
        "  df.drop(columns=['Close time'], inplace=True)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsx7__flzuxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2710fdee-9e07-4d75-a25f-f22c18e90c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-27 03:59:59--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/1m/BTCUSDT-1m-2022-02.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.2, 18.160.213.78, 18.160.213.70, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1795575 (1.7M) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-1m-2022-02.zip’\n",
            "\n",
            "BTCUSDT-1m-2022-02. 100%[===================>]   1.71M  2.29MB/s    in 0.7s    \n",
            "\n",
            "2022-08-27 04:00:00 (2.29 MB/s) - ‘BTCUSDT-1m-2022-02.zip’ saved [1795575/1795575]\n",
            "\n",
            "Archive:  BTCUSDT-1m-2022-02.zip\n",
            "  inflating: BTCUSDT-1m-2022-02.csv  \n",
            "     adding features to 1m...\n",
            " avg gain/loss data is of by 13322.571079015732 timestamps\n",
            " avg gain/loss data is of by 13327.26025724411 timestamps\n",
            "--2022-08-27 04:00:44--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/5m/BTCUSDT-5m-2022-02.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 52.84.18.48, 52.84.18.84, 52.84.18.7, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|52.84.18.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 382801 (374K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-5m-2022-02.zip’\n",
            "\n",
            "BTCUSDT-5m-2022-02. 100%[===================>] 373.83K   756KB/s    in 0.5s    \n",
            "\n",
            "2022-08-27 04:00:45 (756 KB/s) - ‘BTCUSDT-5m-2022-02.zip’ saved [382801/382801]\n",
            "\n",
            "Archive:  BTCUSDT-5m-2022-02.zip\n",
            "  inflating: BTCUSDT-5m-2022-02.csv  \n",
            "     adding features to 5m...\n",
            " avg gain/loss data is of by 13545.797122001648 timestamps\n",
            " avg gain/loss data is of by 13546.46306681633 timestamps\n",
            "--2022-08-27 04:00:51--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/15m/BTCUSDT-15m-2022-02.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 52.84.18.48, 52.84.18.84, 52.84.18.7, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|52.84.18.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 134986 (132K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-15m-2022-02.zip’\n",
            "\n",
            "BTCUSDT-15m-2022-02 100%[===================>] 131.82K   509KB/s    in 0.3s    \n",
            "\n",
            "2022-08-27 04:00:52 (509 KB/s) - ‘BTCUSDT-15m-2022-02.zip’ saved [134986/134986]\n",
            "\n",
            "Archive:  BTCUSDT-15m-2022-02.zip\n",
            "  inflating: BTCUSDT-15m-2022-02.csv  \n",
            "     adding features to 15m...\n",
            " avg gain/loss data is of by 14452.765076875687 timestamps\n",
            " avg gain/loss data is of by 14453.020141363144 timestamps\n",
            "--2022-08-27 04:00:54--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/1h/BTCUSDT-1h-2022-02.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 52.84.18.48, 52.84.18.84, 52.84.18.7, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|52.84.18.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35845 (35K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-1h-2022-02.zip’\n",
            "\n",
            "BTCUSDT-1h-2022-02. 100%[===================>]  35.00K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-08-27 04:00:55 (279 KB/s) - ‘BTCUSDT-1h-2022-02.zip’ saved [35845/35845]\n",
            "\n",
            "Archive:  BTCUSDT-1h-2022-02.zip\n",
            "  inflating: BTCUSDT-1h-2022-02.csv  \n",
            "     adding features to 1h...\n",
            " avg gain/loss data is of by 14455.870036125183 timestamps\n",
            " avg gain/loss data is of by 14455.940204381943 timestamps\n",
            "--2022-08-27 04:00:56--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/1m/BTCUSDT-1m-2022-03.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 52.84.18.48, 52.84.18.84, 52.84.18.7, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|52.84.18.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1922066 (1.8M) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-1m-2022-03.zip’\n",
            "\n",
            "BTCUSDT-1m-2022-03. 100%[===================>]   1.83M  2.42MB/s    in 0.8s    \n",
            "\n",
            "2022-08-27 04:00:57 (2.42 MB/s) - ‘BTCUSDT-1m-2022-03.zip’ saved [1922066/1922066]\n",
            "\n",
            "Archive:  BTCUSDT-1m-2022-03.zip\n",
            "  inflating: BTCUSDT-1m-2022-03.csv  \n",
            "     adding features to 1m...\n",
            " avg gain/loss data is of by 13379.658567428589 timestamps\n",
            " avg gain/loss data is of by 13382.91754078865 timestamps\n",
            "--2022-08-27 04:01:30--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/5m/BTCUSDT-5m-2022-03.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.70, 18.160.213.2, 18.160.213.78, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 412840 (403K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-5m-2022-03.zip’\n",
            "\n",
            "BTCUSDT-5m-2022-03. 100%[===================>] 403.16K   800KB/s    in 0.5s    \n",
            "\n",
            "2022-08-27 04:01:31 (800 KB/s) - ‘BTCUSDT-5m-2022-03.zip’ saved [412840/412840]\n",
            "\n",
            "Archive:  BTCUSDT-5m-2022-03.zip\n",
            "  inflating: BTCUSDT-5m-2022-03.csv  \n",
            "     adding features to 5m...\n",
            " avg gain/loss data is of by 13592.397145748138 timestamps\n",
            " avg gain/loss data is of by 13593.082748889923 timestamps\n",
            "--2022-08-27 04:01:38--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/15m/BTCUSDT-15m-2022-03.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.70, 18.160.213.2, 18.160.213.78, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 146210 (143K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-15m-2022-03.zip’\n",
            "\n",
            "BTCUSDT-15m-2022-03 100%[===================>] 142.78K   390KB/s    in 0.4s    \n",
            "\n",
            "2022-08-27 04:01:39 (390 KB/s) - ‘BTCUSDT-15m-2022-03.zip’ saved [146210/146210]\n",
            "\n",
            "Archive:  BTCUSDT-15m-2022-03.zip\n",
            "  inflating: BTCUSDT-15m-2022-03.csv  \n",
            "     adding features to 15m...\n",
            " avg gain/loss data is of by 14499.820263624191 timestamps\n",
            " avg gain/loss data is of by 14500.616468191147 timestamps\n",
            "--2022-08-27 04:01:44--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/1h/BTCUSDT-1h-2022-03.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.70, 18.160.213.2, 18.160.213.78, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38902 (38K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-1h-2022-03.zip’\n",
            "\n",
            "BTCUSDT-1h-2022-03. 100%[===================>]  37.99K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-08-27 04:01:44 (303 KB/s) - ‘BTCUSDT-1h-2022-03.zip’ saved [38902/38902]\n",
            "\n",
            "Archive:  BTCUSDT-1h-2022-03.zip\n",
            "  inflating: BTCUSDT-1h-2022-03.csv  \n",
            "     adding features to 1h...\n",
            " avg gain/loss data is of by 14505.066704750061 timestamps\n",
            " avg gain/loss data is of by 14505.128865480423 timestamps\n",
            "--2022-08-27 04:01:45--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/1m/BTCUSDT-1m-2022-04.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.70, 18.160.213.2, 18.160.213.78, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1833542 (1.7M) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-1m-2022-04.zip’\n",
            "\n",
            "BTCUSDT-1m-2022-04. 100%[===================>]   1.75M  2.82MB/s    in 0.6s    \n",
            "\n",
            "2022-08-27 04:01:46 (2.82 MB/s) - ‘BTCUSDT-1m-2022-04.zip’ saved [1833542/1833542]\n",
            "\n",
            "Archive:  BTCUSDT-1m-2022-04.zip\n",
            "  inflating: BTCUSDT-1m-2022-04.csv  \n",
            "     adding features to 1m...\n",
            " avg gain/loss data is of by 13428.417887210846 timestamps\n",
            " avg gain/loss data is of by 13431.744352579117 timestamps\n",
            "--2022-08-27 04:02:17--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/5m/BTCUSDT-5m-2022-04.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.70, 18.160.213.46, 18.160.213.78, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 395413 (386K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-5m-2022-04.zip’\n",
            "\n",
            "BTCUSDT-5m-2022-04. 100%[===================>] 386.15K   780KB/s    in 0.5s    \n",
            "\n",
            "2022-08-27 04:02:18 (780 KB/s) - ‘BTCUSDT-5m-2022-04.zip’ saved [395413/395413]\n",
            "\n",
            "Archive:  BTCUSDT-5m-2022-04.zip\n",
            "  inflating: BTCUSDT-5m-2022-04.csv  \n",
            "     adding features to 5m...\n",
            " avg gain/loss data is of by 13638.972999572754 timestamps\n",
            " avg gain/loss data is of by 13639.64909696579 timestamps\n",
            "--2022-08-27 04:02:24--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/15m/BTCUSDT-15m-2022-04.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.70, 18.160.213.46, 18.160.213.78, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140328 (137K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-15m-2022-04.zip’\n",
            "\n",
            "BTCUSDT-15m-2022-04 100%[===================>] 137.04K   372KB/s    in 0.4s    \n",
            "\n",
            "2022-08-27 04:02:25 (372 KB/s) - ‘BTCUSDT-15m-2022-04.zip’ saved [140328/140328]\n",
            "\n",
            "Archive:  BTCUSDT-15m-2022-04.zip\n",
            "  inflating: BTCUSDT-15m-2022-04.csv  \n",
            "     adding features to 15m...\n",
            " avg gain/loss data is of by 14546.182940006256 timestamps\n",
            " avg gain/loss data is of by 14546.424938678741 timestamps\n",
            "--2022-08-27 04:02:28--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/1h/BTCUSDT-1h-2022-04.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.70, 18.160.213.46, 18.160.213.78, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37360 (36K) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-1h-2022-04.zip’\n",
            "\n",
            "BTCUSDT-1h-2022-04. 100%[===================>]  36.48K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-08-27 04:02:29 (286 KB/s) - ‘BTCUSDT-1h-2022-04.zip’ saved [37360/37360]\n",
            "\n",
            "Archive:  BTCUSDT-1h-2022-04.zip\n",
            "  inflating: BTCUSDT-1h-2022-04.csv  \n",
            "     adding features to 1h...\n",
            " avg gain/loss data is of by 14549.32364654541 timestamps\n",
            " avg gain/loss data is of by 14549.38567686081 timestamps\n",
            "--2022-08-27 04:02:30--  https://data.binance.vision/data/futures/um/monthly/klines/BTCUSDT/1m/BTCUSDT-1m-2022-05.zip\n",
            "Resolving data.binance.vision (data.binance.vision)... 18.160.213.70, 18.160.213.46, 18.160.213.78, ...\n",
            "Connecting to data.binance.vision (data.binance.vision)|18.160.213.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1926173 (1.8M) [binary/octet-stream]\n",
            "Saving to: ‘BTCUSDT-1m-2022-05.zip’\n",
            "\n",
            "BTCUSDT-1m-2022-05. 100%[===================>]   1.84M  2.94MB/s    in 0.6s    \n",
            "\n",
            "2022-08-27 04:02:30 (2.94 MB/s) - ‘BTCUSDT-1m-2022-05.zip’ saved [1926173/1926173]\n",
            "\n",
            "Archive:  BTCUSDT-1m-2022-05.zip\n",
            "  inflating: BTCUSDT-1m-2022-05.csv  \n",
            "     adding features to 1m...\n",
            " avg gain/loss data is of by 13472.687148332596 timestamps\n",
            " avg gain/loss data is of by 13475.961619377136 timestamps\n"
          ]
        }
      ],
      "source": [
        "intervals=['1m', '5m', '15m', '1h']\n",
        "months=['02','03','04','05']\n",
        "df=get_df(intervals,months)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Close'][170:180].plot()"
      ],
      "metadata": {
        "id": "9RRrkBEyAP_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['RSI5m'][170:180].plot()"
      ],
      "metadata": {
        "id": "Whby8FP6IgoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['macd5m'][170:180].plot()"
      ],
      "metadata": {
        "id": "fWlUaUHoAHOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88xcPqual5_s"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "  print(df[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfjqaaV6dt6v"
      },
      "outputs": [],
      "source": [
        "df[63250:63295]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPCIdQC-Ssj_"
      },
      "outputs": [],
      "source": [
        "df_test=get_df(['1m', '5m', '15m', '1h'],['06', '07'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFKVp7TNccf7"
      },
      "outputs": [],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnF2XqyIiZPL"
      },
      "outputs": [],
      "source": [
        "def Write_to_file(Date, net_worth, filename='{}.txt'.format(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))):\n",
        "  datestr=''\n",
        "  for i in net_worth:\n",
        "    #print(i)\n",
        "    datestr += \" {}\".format(str(i))\n",
        "    #print(Date)\n",
        "  if not os.path.exists('logs'):\n",
        "    os.makedirs('logs')\n",
        "  file = open(\"logs/\"+filename, 'a+')\n",
        "  file.write(datestr+\"\\n\")\n",
        "  file.close()\n",
        "\n",
        "class TradingGraph:\n",
        "    # A crypto trading visualization using matplotlib made to render custom prices which come in following way:\n",
        "    # Date, Open, High, Low, Close, Volume, net_worth, trades\n",
        "    # call render every step\n",
        "    def __init__(self, Render_range):\n",
        "        self.Volume = deque(maxlen=Render_range)\n",
        "        self.net_worth = deque(maxlen=Render_range)\n",
        "        self.render_data = deque(maxlen=Render_range)\n",
        "        self.Render_range = Render_range\n",
        "\n",
        "        # We are using the style ‘ggplot’\n",
        "        plt.style.use('ggplot')\n",
        "        # close all plots if there are open\n",
        "        plt.close('all')\n",
        "        # figsize attribute allows us to specify the width and height of a figure in unit inches\n",
        "        self.fig = plt.figure(figsize=(16,8)) \n",
        "\n",
        "        # Create top subplot for price axis\n",
        "        self.ax1 = plt.subplot2grid((6,1), (0,0), rowspan=5, colspan=1)\n",
        "        \n",
        "        # Create bottom subplot for volume which shares its x-axis\n",
        "        self.ax2 = plt.subplot2grid((6,1), (5,0), rowspan=1, colspan=1, sharex=self.ax1)\n",
        "        \n",
        "        # Create a new axis for net worth which shares its x-axis with price\n",
        "        self.ax3 = self.ax1.twinx()\n",
        "\n",
        "        # Formatting Date\n",
        "        self.date_format = mpl_dates.DateFormatter('%d-%m-%Y')\n",
        "        #self.date_format = mpl_dates.DateFormatter('%d-%m-%Y')\n",
        "        \n",
        "        # Add paddings to make graph easier to view\n",
        "        #plt.subplots_adjust(left=0.07, bottom=-0.1, right=0.93, top=0.97, wspace=0, hspace=0)\n",
        "\n",
        "    # Render the environment to the screen\n",
        "    def render(self, Date, Open, High, Low, Close, Volume, net_worth, trades):\n",
        "        # append volume and net_worth to deque list\n",
        "        self.Volume.append(Volume)\n",
        "        self.net_worth.append(net_worth)\n",
        "\n",
        "        # before appending to deque list, need to convert Date to special format\n",
        "        Date = mpl_dates.date2num([pd.to_datetime(Date, unit='ms')])[0]\n",
        "        self.render_data.append([Date, Open, High, Low, Close])\n",
        "        \n",
        "        # Clear the frame rendered last step\n",
        "        self.ax1.clear()\n",
        "        candlestick_ohlc(self.ax1, self.render_data, width=0.015/24, colorup='green', colordown='red', alpha=0.8)\n",
        "\n",
        "        # Put all dates to one list and fill ax2 sublot with volume\n",
        "        Date_Render_range = [i[0] for i in self.render_data]\n",
        "        self.ax2.clear()\n",
        "        self.ax2.fill_between(Date_Render_range, self.Volume, 0)\n",
        "\n",
        "        # draw our net_worth graph on ax3 (shared with ax1) subplot\n",
        "        self.ax3.clear()\n",
        "        self.ax3.plot(Date_Render_range, self.net_worth, color=\"blue\")\n",
        "        \n",
        "        # beautify the x-labels (Our Date format)\n",
        "        self.ax1.xaxis.set_major_formatter(self.date_format)\n",
        "        self.fig.autofmt_xdate()\n",
        "\n",
        "        # sort sell and buy orders, put arrows in appropiate order positions\n",
        "        for trade in trades:\n",
        "            trade_date = mpl_dates.date2num([pd.to_datetime(trade['Date'], unit='ms')])[0]\n",
        "            if trade_date in Date_Render_range:\n",
        "                if trade['type'] == 'open_long':\n",
        "                    high_low = trade['Low']-10\n",
        "                    self.ax1.scatter(trade_date, high_low, c='white', label='white', s = 180, edgecolors='green', marker=\"^\")\n",
        "                elif trade['type'] == 'open_short':\n",
        "                    high_low = trade['High']+10\n",
        "                    self.ax1.scatter(trade_date, high_low, c='white', label='white', s = 180, edgecolors='red', marker=\"v\")\n",
        "                elif trade['type'] == 'close_long':\n",
        "                    high_low = trade['High']+10\n",
        "                    self.ax1.scatter(trade_date, high_low, c='black', label='black', s = 180, edgecolors='red', marker=\"v\")\n",
        "                elif trade['type'] == 'close_short':\n",
        "                    high_low = trade['Low']-10\n",
        "                    self.ax1.scatter(trade_date, high_low, c='black', label='black', s = 180, edgecolors='green', marker=\"^\")\n",
        "\n",
        "        # we need to set layers every step, because we are clearing subplots every step\n",
        "        self.ax2.set_xlabel('Date')\n",
        "        self.ax1.set_ylabel('Price')\n",
        "        self.ax3.set_ylabel('Balance')\n",
        "\n",
        "        # I use tight_layout to replace plt.subplots_adjust\n",
        "        self.fig.tight_layout()\n",
        "\n",
        "        \"\"\"Display image with matplotlib - interrupting other tasks\"\"\"\n",
        "        # Show the graph without blocking the rest of the program\n",
        "        plt.show(block=False)\n",
        "        # Necessary to view frames before they are unrendered\n",
        "        #plt.pause(0.0001)\n",
        "        output.clear()\n",
        "        #time.sleep(1)\n",
        "\n",
        "        \"\"\"Display image with OpenCV - no interruption\"\"\"\n",
        "        # redraw the canvas\n",
        "        self.fig.canvas.draw()\n",
        "        # convert canvas to image\n",
        "        img = np.fromstring(self.fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
        "        img  = img.reshape(self.fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "        # img is rgb, convert to opencv's default bgr\n",
        "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # display image with OpenCV or any operation you like\n",
        "        cv2_imshow(image)\n",
        "\n",
        "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
        "            cv2.destroyAllWindows()\n",
        "            return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w3lMw0f0j_g"
      },
      "outputs": [],
      "source": [
        "class CustomEnv:\n",
        "    def __init__(self, df, initial_balance=100, init_postition_size=10, leverage=125, max_steps=0, lookback_window_size=240, Render_range=120, visualize=False):\n",
        "        self.df = df.dropna().reset_index()\n",
        "        self.df.drop(columns=['index'], inplace=True)\n",
        "        print('Feature list in df: ', end=' ')\n",
        "        for col in self.df.columns:\n",
        "          print(col, end=\", \")\n",
        "        print()\n",
        "        self.df_total_steps = len(self.df)-1\n",
        "        self.max_steps = max_steps\n",
        "        self.initial_balance = initial_balance\n",
        "        self.balance = initial_balance-init_postition_size\n",
        "        self.position_size = init_postition_size\n",
        "        self.init_postition_size = init_postition_size\n",
        "        self.leverage = leverage\n",
        "        self.lookback_window_size = lookback_window_size\n",
        "        self.Render_range = Render_range\n",
        "        self.visualize = visualize\n",
        "\n",
        "        # features(col names) to exclude from env state\n",
        "        self.exclude_list=['Open time', 'Open', 'High', 'Low', 'Close']\n",
        "\n",
        "        # Action space from 0 to 3, 0 is hold, 1 is buy, 2 is sell\n",
        "        self.action_space = np.array([0, 1, 2])\n",
        "        self.action_space_n = len(self.action_space)\n",
        "\n",
        "        # Orders history contains the balance, net_worth, crypto_bought, crypto_sold, crypto_held values for the last lookback_window_size steps\n",
        "        self.orders_history = deque(maxlen=self.lookback_window_size)\n",
        "        \n",
        "        # Market history contains the OHCL values for the last lookback_window_size prices\n",
        "        self.market_history = deque(maxlen=self.lookback_window_size)\n",
        "\n",
        "        # State size contains Market+Orders history for the last lookback_window_size steps\n",
        "        self.state_size = (self.lookback_window_size, len(self.df.columns)+5)\n",
        "\n",
        "    # Reset the state of the environment to an initial state\n",
        "    def reset(self, env_steps_size = 0):\n",
        "        if self.max_steps>0: env_steps_size=self.max_steps\n",
        "        if self.visualize: \n",
        "          self.trades = []\n",
        "          self.visualization = TradingGraph(Render_range=self.Render_range) # init visualization\n",
        "        self.position_size=0\n",
        "        self.balance=self.initial_balance\n",
        "        self.qty=0\n",
        "        self.enter_price=None\n",
        "        self.in_position=False\n",
        "        self.in_position_log=[self.in_position, self.in_position]\n",
        "        self.in_position_counter=0\n",
        "        self.pnl=0\n",
        "        self.episode_orders = 0\n",
        "        self.good_trades_count=1\n",
        "        self.good_trades=[]\n",
        "        self.bad_trades_count=1\n",
        "        self.bad_trades=[]\n",
        "        self.pnl_list=[self.pnl,self.pnl]\n",
        "        self.cumulative_pnl=0\n",
        "        self.balance_history=[self.balance,self.balance]\n",
        "        self.reward=0\n",
        "\n",
        "        if env_steps_size > 0: # used for training dataset\n",
        "            self.start_step = random.randint(self.lookback_window_size, self.df_total_steps - env_steps_size)\n",
        "            self.end_step = self.start_step + env_steps_size\n",
        "        else: # used for testing dataset\n",
        "            self.start_step = random.randint(self.lookback_window_size, self.df_total_steps)\n",
        "            self.end_step = self.df_total_steps\n",
        "        self.current_step = self.start_step\n",
        "\n",
        "        for i in reversed(range(self.lookback_window_size)):\n",
        "            current_step = self.current_step - i\n",
        "            self.orders_history.append([self.position_size, self.balance, self.in_position, self.qty, self.cumulative_pnl, self.pnl, self.enter_price])\n",
        "            self.market_history.append([self.df.loc[self.current_step, col_name] for col_name in self.df.columns if col_name not in self.exclude_list])\n",
        "            #print(i, end=': ')\n",
        "            #print()\n",
        "            #print(self.orders_history[-1])\n",
        "            #print(self.market_history[-1])\n",
        "\n",
        "        state = np.concatenate((self.market_history, self.orders_history), axis=1)\n",
        "        #print(state)\n",
        "        return state\n",
        "\n",
        "    # Get the data points for the given current_step\n",
        "    def _next_observation(self):\n",
        "      self.market_history.append([self.df.loc[self.current_step, col_name] for col_name in self.df.columns if col_name not in self.exclude_list])\n",
        "      obs = np.concatenate((self.market_history, self.orders_history), axis=1)\n",
        "      #print(obs)\n",
        "      #time.sleep(120)\n",
        "      return obs\n",
        "    \n",
        "    def _calculate_reward(self):\n",
        "      ###### Profit closing ######\n",
        "      if (not self.in_position) and self.in_position_log[-2]==True and (self.position_size>round(self.init_postition_size*0.999, 2)):\n",
        "        self.good_trades_count+=1\n",
        "        self.good_trades.append(self.position_size/round(self.init_postition_size*0.999, 2)-1)\n",
        "        if self.cumulative_pnl>0:\n",
        "          self.reward=self.cumulative_pnl\n",
        "        elif self.cumulative_pnl<0:\n",
        "          self.cumulative_pnl=(-1)*self.cumulative_pnl\n",
        "        #self.reward=(self.balance/self.balance_history[-2]-1)+abs(self.cumulative_pnl)*1\n",
        "        #self.reward=2+(self.bad_trades_count/self.good_trades_count)+self.orders_history[-2][-2]\n",
        "        self.reward=5+(self.bad_trades_count/self.good_trades_count)+self.cumulative_pnl\n",
        "      ###### Loss closing ######\n",
        "      elif (not self.in_position) and self.in_position_log[-2]==True and (self.position_size<round(self.init_postition_size*0.999, 2)):\n",
        "        self.bad_trades_count+=1\n",
        "        self.bad_trades.append(self.position_size/round(self.init_postition_size*0.999, 2)-1)\n",
        "        if self.cumulative_pnl<0:\n",
        "          self.reward=self.cumulative_pnl\n",
        "        elif self.cumulative_pnl>0:\n",
        "          self.cumulative_pnl=(-1)*self.cumulative_pnl\n",
        "        #self.reward=(self.balance_history[-2]/self.balance-1)*(-1)-abs(self.cumulative_pnl)*1\n",
        "        #self.reward=1/abs(self.cumulative_pnl)\n",
        "        #self.reward=-2-(self.bad_trades_count/self.good_trades_count)+self.orders_history[-2][-2]\n",
        "        self.reward=-5-(self.bad_trades_count/self.good_trades_count)+self.cumulative_pnl\n",
        "      ###### Holding position ######\n",
        "      #elif self.pnl<0 and self.pnl_list[-2]>0:\n",
        "        #if self.cumulative_pnl<0:\n",
        "          #self.cumulative_pnl=self.cumulative_pnl\n",
        "          #self.reward=self.cumulative_pnl\n",
        "        #elif self.cumulative_pnl>0:\n",
        "          #self.cumulative_pnl=(-1)*self.cumulative_pnl\n",
        "          #self.cumulative_pnl=self.cumulative_pnl\n",
        "          #self.reward=self.cumulative_pnl\n",
        "        #self.reward=self.pnl\n",
        "        #self.reward=self.pnl-self.pnl_list[-2]\n",
        "      #elif self.pnl>0 and self.pnl_list[-2]<0:\n",
        "        #self.reward=self.pnl*10\n",
        "        #self.cumulative_pnl=0\n",
        "        #self.reward=self.pnl\n",
        "        #self.reward=self.pnl-self.pnl_list[-2]\n",
        "      elif self.in_position:\n",
        "        self.reward=self.pnl\n",
        "        '''if self.pnl<0 and self.pnl_list[-2]>0:\n",
        "          self.reward=self.pnl\n",
        "        elif self.pnl>0 and self.pnl_list[-2]<0:\n",
        "          self.reward=self.pnl\n",
        "        else:\n",
        "          if self.pnl>0:\n",
        "            self.reward=self.pnl/self.in_position_counter\n",
        "          elif self.pnl<0:\n",
        "            self.reward=self.pnl\n",
        "          else:\n",
        "            self.reward=0'''\n",
        "        '''if self.pnl>0:\n",
        "          if self.cumulative_pnl>0:\n",
        "            self.reward=self.cumulative_pnl/self.in_position_counter\n",
        "          elif self.cumulative_pnl<0:\n",
        "            self.cumulative_pnl=(-1)*self.cumulative_pnl\n",
        "            self.cumulative_pnl=self.cumulative_pnl\n",
        "            self.reward=self.cumulative_pnl/self.in_position_counter\n",
        "        elif self.pnl<0:\n",
        "          if self.cumulative_pnl<0:\n",
        "            self.reward=self.cumulative_pnl\n",
        "          elif self.cumulative_pnl>0:\n",
        "            self.cumulative_pnl=(-1)*self.cumulative_pnl\n",
        "            self.cumulative_pnl=self.cumulative_pnl\n",
        "            self.reward=self.cumulative_pnl\n",
        "        else:\n",
        "          self.reward=self.pnl'''\n",
        "      else:\n",
        "        #self.reward=self.cumulative_pnl\n",
        "        #self.reward=self.pnl\n",
        "        self.reward=0\n",
        "      return self.reward\n",
        "\n",
        "    def _get_pnl(self, current_price):\n",
        "      self.pnl=(((current_price/self.enter_price)-1)*self.leverage)*self.qty\n",
        "      self.pnl_list.append(self.pnl)\n",
        "      if self.cumulative_pnl>0 and len(self.pnl_list)>1:\n",
        "        self.cumulative_pnl+=(self.pnl-self.pnl_list[-2])\n",
        "      else:\n",
        "        self.cumulative_pnl+=self.pnl\n",
        "      #self.cumulative_pnl+=self.pnl\n",
        "      return self.pnl\n",
        "\n",
        "    def _finish_episode(self, penalty=True):\n",
        "      self.orders_history.append([self.position_size, self.balance, self.in_position, self.qty, self.cumulative_pnl, self.pnl, self.enter_price])\n",
        "      self._calculate_reward()\n",
        "      done=True\n",
        "      obs = self._next_observation()\n",
        "      if len(self.balance_history)>0 and len(self.good_trades)>0 and len(self.bad_trades)>0:\n",
        "        print('')\n",
        "        print(f' Koncowy balans: ${self.balance:.2f} Sredni balans: ${mean(self.balance_history):.2f} Max balans: ${max(self.balance_history):.2f} zyskownych:{self.good_trades_count:} ({mean(self.good_trades)*100:.1f}%) stratnych:{self.bad_trades_count} ({mean(self.bad_trades)*100:.1f}%)')\n",
        "      else:\n",
        "        print('')\n",
        "        print(f' Koncowy balans: ${self.balance:.2f} Max balans: ${max(self.balance_history):.2f} zyskownych:{self.good_trades_count} stratnych:{self.bad_trades_count}')\n",
        "      info = {'action': 0,\n",
        "              'reward': self.reward,\n",
        "              'step': self.current_step}\n",
        "      return obs, (mean(self.balance_history)-self.initial_balance)*self.leverage, done, info\n",
        "\n",
        "    def _open_position(self, side, price):\n",
        "      self.in_position=True\n",
        "      self.in_position_log.append(self.in_position)\n",
        "      self.episode_orders += 1\n",
        "      self.enter_price=price\n",
        "      #print(f' BEFORE self.position_size: {self.position_size}')\n",
        "      #print(f' BEFORE self.balance: {self.balance}')\n",
        "      self.position_size = round(self.init_postition_size*0.999, 2)\n",
        "      self.balance-=self.init_postition_size\n",
        "      #print(f' AFTER self.position_size: {self.position_size}')\n",
        "      #print(f' AFTER self.balance: {self.balance}')\n",
        "      self.balance_history.append(self.balance)\n",
        "      if side=='long':\n",
        "        self.qty = 1  #*(self.position_size/self.enter_price)\n",
        "      elif side=='short':\n",
        "        self.qty= -1  #(self.position_size/self.enter_price)\n",
        "\n",
        "    def _close_position(self):\n",
        "      self.qty = 0\n",
        "      self.in_position=False\n",
        "      self.in_position_log.append(self.in_position)\n",
        "      self.in_position_counter=0\n",
        "      if self.pnl>0:\n",
        "        self.good_trades_count += 1\n",
        "      elif self.pnl<0:\n",
        "        self.bad_trades_count += 1\n",
        "      #print(f' self.pnl: {self.pnl}')\n",
        "      #print(f' BEFORE self.position_size: {self.position_size}')\n",
        "      #print(f' BEFORE self.balance: {self.balance}')\n",
        "      self.position_size += round((self.position_size*self.pnl)*0.999, 2)\n",
        "      self.balance += self.position_size\n",
        "      if self.balance>self.initial_balance: self.init_postition_size=round(self.balance/10, 2)\n",
        "      #print(f' AFTER self.position_size: {self.position_size}')\n",
        "      #print(f' AFTER self.balance: {self.balance}')\n",
        "      self.balance_history.append(self.balance)\n",
        "      self.pnl = 0\n",
        "      self.cumulative_pnl = 0\n",
        "    \n",
        "    # Execute one time step within the environment\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        if self.current_step==self.end_step:\n",
        "          return self._finish_episode(penalty=False)\n",
        "        done=False\n",
        "        self.in_position_log.append(self.in_position)\n",
        "        close=self.df.loc[self.current_step, 'Close']\n",
        "        current_price = random.uniform(round(close*1.0002, 2), round(close*0.9998, 2))\n",
        "        #current_price=self.df.loc[self.current_step, 'Close']\n",
        "        #current_price = random.uniform(self.df.loc[self.current_step, 'High'], self.df.loc[self.current_step, 'Low'])\n",
        "        ########################## VISUALIZATION ###############################\n",
        "        if self.visualize:\n",
        "          Date = self.df.loc[self.current_step, 'Open time']\n",
        "          High = self.df.loc[self.current_step, 'High']\n",
        "          Low = self.df.loc[self.current_step, 'Low']\n",
        "        ########################################################################\n",
        "        if self.in_position:\n",
        "          self._get_pnl(current_price)\n",
        "          if self.pnl<=-0.9:\n",
        "            self._close_position()\n",
        "            #return self._finish_episode()\n",
        "          else:\n",
        "            ##CLOSING POSTIONS OR PASS##\n",
        "            if action == 0:\n",
        "              #print('IN POSITION PASS')\n",
        "              pass\n",
        "            # Close SHORT or LONG qty={-1,0,1}\n",
        "            elif (action==1 and self.qty<0) or (action==2 and self.qty>0):\n",
        "              #print('CLOSING POSITION')\n",
        "              self._close_position()\n",
        "              ########################## VISUALIZATION ###############################\n",
        "              if self.visualize and action==1:  self.trades.append({'Date' : Date, 'High' : High, 'Low' : Low, 'total': self.qty, 'type': \"close_short\"})\n",
        "              elif self.visualize and action==2:  self.trades.append({'Date' : Date, 'High' : High, 'Low' : Low, 'total': self.qty, 'type': \"close_long\"})\n",
        "              ########################################################################\n",
        "              if self.balance*0.999<=self.init_postition_size:\n",
        "                return self._finish_episode()\n",
        "        ##OPENING POSTIONS OR PASS##\n",
        "        else:\n",
        "          if action == 0:\n",
        "            #print('NO POSITION PASS')\n",
        "            pass\n",
        "          # OPEN LONG\n",
        "          elif self.balance*0.999<=self.init_postition_size:\n",
        "            return self._finish_episode()\n",
        "          elif action == 1:\n",
        "            #print('OPENING LONG')\n",
        "            self._open_position('long', current_price)\n",
        "            if self.visualize: self.trades.append({'Date' : Date, 'High' : High, 'Low' : Low, 'total': self.qty, 'type': \"open_long\"})\n",
        "          # OPEN SHORT\n",
        "          elif action == 2:\n",
        "            #print('OPENING SHORT')\n",
        "            self._open_position('short', current_price)\n",
        "            if self.visualize: self.trades.append({'Date' : Date, 'High' : High, 'Low' : Low, 'total': self.qty, 'type': \"open_short\"})\n",
        "        \n",
        "        self.orders_history.append([self.position_size, self.balance, self.in_position, self.qty, self.cumulative_pnl, self.pnl, self.enter_price])\n",
        "        if self.in_position: self.in_position_counter+=1\n",
        "        #Write_to_file(Date, self.orders_history[-1])\n",
        "        self._calculate_reward()\n",
        "        obs = self._next_observation()\n",
        "        info = {'action': action,\n",
        "                'reward': self.reward,\n",
        "                'step': self.current_step}\n",
        "        return obs, self.reward, done, info\n",
        "\n",
        "    # render environment\n",
        "    def render(self, visualize=False, *args, **kwargs):\n",
        "      if visualize or self.visualize:\n",
        "        Date = self.df.loc[self.current_step, 'Open time']\n",
        "        Open = self.df.loc[self.current_step, 'Open']\n",
        "        Close = self.df.loc[self.current_step, 'Close']\n",
        "        High = self.df.loc[self.current_step, 'High']\n",
        "        Low = self.df.loc[self.current_step, 'Low']\n",
        "        Volume = self.reward\n",
        "        # Render the environment to the screen\n",
        "        self.visualization.render(Date, Open, High, Low, Close, Volume, self.balance, self.trades)\n",
        "\n",
        "lookback_window_size = 60\n",
        "\n",
        "train_env = CustomEnv(df, lookback_window_size=lookback_window_size, max_steps=4320, visualize=True, initial_balance=100, leverage=50)\n",
        "test_env = CustomEnv(df_test, lookback_window_size=lookback_window_size, max_steps=1440, visualize=True, initial_balance=100, leverage=50)\n",
        "\n",
        "def build_model(states, actions, neurons, layers_set, window_length, lookback_window_size):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(window_length,lookback_window_size,states)))\n",
        "    #model.add(Reshape((lookback_window_size, states), input_shape=(window_length, lookback_window_size, states)))\n",
        "    #model.add(LSTM(neurons, return_sequences = True, input_shape=(lookback_window_size, states), activation = 'relu'))\n",
        "    #model.add(Dense(states, activation='relu'))\n",
        "    #model.add(Flatten(input_shape=(window_length,lookback_window_size,states)))\n",
        "    for k in layers_set.values():\n",
        "      model.add(Dense(k, activation='relu'))\n",
        "    model.add(Dense(actions, activation='linear'))\n",
        "    return model\n",
        "def build_agent(model, actions, window_length, lookback_window_size, policy=EpsGreedyQPolicy()):\n",
        "    #policy = BoltzmannQPolicy()\n",
        "    test_policy=policy\n",
        "    memory = SequentialMemory(limit=100*window_length, window_length=window_length)\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy, test_policy=test_policy,\n",
        "                  nb_actions=actions, nb_steps_warmup=lookback_window_size*10, target_model_update=1e-1, enable_double_dqn=True, enable_dueling_network=True, dueling_type='avg')\n",
        "    return dqn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "policy=EpsGreedyQPolicy()\n",
        "scores_l=[]\n",
        "while True:\n",
        "      lookback_size=random.choice(list(range(1,90,1)))\n",
        "      n_count=int((lookback_size*len(df.columns)+3)//2)\n",
        "      n_counts=list(range(n_count//16,n_count,n_count//16))\n",
        "      n_layers=list(range(1,6))\n",
        "      layers_set={}\n",
        "      for i in range(random.choice(n_layers)):\n",
        "        layers_set[i]=random.choice(n_counts)\n",
        "      n_windows=random.choice(list(range(1,2)))\n",
        "\n",
        "      train_env = CustomEnv(df, lookback_window_size=lookback_size, max_steps=1440, visualize=True, initial_balance=20, init_postition_size=2.0, leverage=125)\n",
        "      test_env = CustomEnv(df_test, lookback_window_size=lookback_size, visualize=True, initial_balance=20, init_postition_size=2.0, leverage=125)\n",
        "\n",
        "      model = build_model(len(train_env.reset()[-1]), train_env.action_space_n, n_count, layers_set, n_windows, lookback_size)\n",
        "      #model.summary()\n",
        "      dqn = build_agent(model, train_env.action_space_n, n_windows, lookback_size, policy=policy)\n",
        "      dqn.compile(Adam(learning_rate=1e-9), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "      ## Callbacks:\n",
        "      #tfboard = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "      #dqn.fit(train_env, nb_steps=100000, visualize=False, callbacks=[tfboard], verbose=2, log_interval=250)\n",
        "      dqn.fit(train_env, nb_steps=10_000, visualize=False, verbose=2, log_interval=250)\n",
        "  \n",
        "      scores = dqn.test(test_env, nb_episodes=10, visualize=False)\n",
        "      scores_l.append([n_windows,n_layers,n_count,scores])\n",
        "      cv = lambda x: abs(np.std(x, ddof=1) / np.mean(x)) * 100\n",
        "      median=np.median(scores.history['episode_reward'])\n",
        "      mean_r=np.mean(scores.history['episode_reward'])\n",
        "      zm=cv(scores.history['episode_reward'])\n",
        "      print(\"####################################################\")\n",
        "      print(f'n_windows: {n_windows}', end='  ')\n",
        "      #print(f'layers_count: {layers_set.keys()}', end='  ')\n",
        "      print(f'layers_size: {layers_set.values()}', end='  ')\n",
        "      print(f'lookback_size: {lookback_size}')\n",
        "      print(f'mediana: {median}', end='  ')\n",
        "      print(f'srednia: {mean_r}', end=' ')\n",
        "      print(f'wsp. zmiennosci: {zm:.1f}%')\n",
        "      if zm<=50 and median>0 and mean_r>0:\n",
        "        model_dir=f'/content/drive/MyDrive/RLtrader/models/WspZm-{zm:.0f}/'\n",
        "        os.makedirs(model_dir)\n",
        "        filepath=f'Me-{median:.0f}window-{n_windows}look-{lookback_size}Layers-{layers_set.values()}.h5'\n",
        "        dqn.save_weights(model_dir+filepath, overwrite=False)\n",
        "        print(f\"#### Zapisano model: {filepath} #####\")\n",
        "      print(\"####################################################\")"
      ],
      "metadata": {
        "id": "pnMHQwmyN452"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_DX1y-mrILr"
      },
      "outputs": [],
      "source": [
        "n_windows=1\n",
        "#n_count=8192\n",
        "n_layers=5\n",
        "policy=EpsGreedyQPolicy()\n",
        "\n",
        "window_sizes=list(range(1,10,1))\n",
        "scores_l=[]\n",
        "for window in window_sizes:\n",
        "      train_env = CustomEnv(df, lookback_window_size=window, max_steps=3000, visualize=True, initial_balance=20, init_postition_size=2.0, leverage=125)\n",
        "      test_env = CustomEnv(df_test, lookback_window_size=window, max_steps=20_000, visualize=True, initial_balance=20, init_postition_size=2.0, leverage=125)\n",
        "      n_count=int(window*len(df.columns)+3//2)\n",
        "\n",
        "      model = build_model(len(train_env.reset()[-1]), train_env.action_space_n, n_count, n_layers, n_windows, window)\n",
        "      #model.summary()\n",
        "      dqn = build_agent(model, train_env.action_space_n, n_windows, window, policy=policy)\n",
        "      dqn.compile(Adam(learning_rate=1e-5), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "      ## Callbacks:\n",
        "      #tfboard = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "      #dqn.fit(train_env, nb_steps=100000, visualize=False, callbacks=[tfboard], verbose=2, log_interval=250)\n",
        "      dqn.fit(train_env, nb_steps=25_000, visualize=False, verbose=2, log_interval=250)\n",
        "  \n",
        "      scores = dqn.test(test_env, nb_episodes=10, visualize=False)\n",
        "      scores_l.append([n_windows,n_layers,n_count,scores])\n",
        "      print(\"####################################################\")\n",
        "      print(f'n_windows: {n_windows}', end='  ')\n",
        "      print(f'n_layers: {n_layers}', end='  ')\n",
        "      print(f'n_count: {n_count}', end='  ')\n",
        "      print(f'window: {window}')\n",
        "      cv = lambda x: abs(np.std(x, ddof=1) / np.mean(x)) * 100 \n",
        "      print('mediana: ', end='  ')\n",
        "      print(np.median(scores.history['episode_reward']), end='  ')\n",
        "      print('srednia: ', end=' ')\n",
        "      print(np.mean(scores.history['episode_reward']), end='  ')\n",
        "      zm=cv(scores.history['episode_reward'])\n",
        "      model_dir=f'/content/drive/MyDrive/RLtrader/models/Me{median:.0f}/'\n",
        "      os.makedirs(model_dir)\n",
        "      filepath=f'WspZm{zm:.0f}win{n_windows}look{lookback_size}L{layers_set.values()}.h5'\n",
        "      if zm<=100 and median>1_000: dqn.save_weights(model_dir+filepath, overwrite=False)\n",
        "      print(f'wsp. zmiennosci: {zm:.1f}%')\n",
        "      print(\"####################################################\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzgFPh0LpBwB"
      },
      "outputs": [],
      "source": [
        "scores_l=[]\n",
        "for n_windows in range(1,2):\n",
        "  for n_layers in range(4,5):\n",
        "    for n_count in range(3240,19440,3240):\n",
        "      model = build_model(len(train_env.reset()[-1]), train_env.action_space_n, n_count, n_layers, n_windows)\n",
        "      #model.summary()\n",
        "      dqn = build_agent(model, train_env.action_space_n, n_windows, EpsGreedyQPolicy())\n",
        "      dqn.compile(Adam(learning_rate=1e-5), metrics=['mae'])\n",
        "      #tfboard = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "      #dqn.fit(train_env, nb_steps=20000, visualize=False, callbacks=[tfboard], verbose=2, log_interval=250)\n",
        "      dqn.fit(train_env, nb_steps=20000, visualize=False, callbacks=[tfboard], verbose=2, log_interval=250)\n",
        "  \n",
        "      scores = dqn.test(test_env, nb_episodes=100, visualize=False)\n",
        "      scores_l.append([n_windows,n_layers,n_count,scores])\n",
        "      print(\"####################################################\")\n",
        "      print(f'n_windows: {n_windows}', end='  ')\n",
        "      print(f'n_layers: {n_layers}', end='  ')\n",
        "      print(f'n_count: {n_count}')\n",
        "      cv = lambda x: abs(np.std(x, ddof=1) / np.mean(x)) * 100 \n",
        "      print('mediana: ', end='  ')\n",
        "      print(np.median(scores.history['episode_reward']), end='  ')\n",
        "      print('srednia: ', end=' ')\n",
        "      print(np.mean(scores.history['episode_reward']), end='  ')\n",
        "      zm=cv(scores.history['episode_reward'])\n",
        "      print(f'wsp. zmiennosci: {zm:.1f}%')\n",
        "      print(\"####################################################\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yywhB0rAO1wd"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir Graph/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eohPo1Gc7AoY"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg0epQOMjZmL"
      },
      "outputs": [],
      "source": [
        "def Random_games(env, visualize=False, train_episodes = 100, training_batch_size=500):\n",
        "    average_net_worth=[]\n",
        "    list_of_orders=[]\n",
        "    rewards=0\n",
        "    list_of_rewards=[]\n",
        "    list_of_mean_rewards=[]\n",
        "    list_of_time=[]\n",
        "    start_time=time.time()\n",
        "    env.visualize=visualize\n",
        "    for episode in range(train_episodes):\n",
        "        print(f' ep{episode}:', end=' ')\n",
        "        env.reset(env_steps_size = training_batch_size)\n",
        "        while True:\n",
        "            if visualize: env.render(visualize)\n",
        "\n",
        "            action = np.random.randint(3, size=1)[0]\n",
        "\n",
        "            state, reward, done, info = env.step(action)\n",
        "            rewards+=reward\n",
        "            #print(f'rewards: {rewards}')\n",
        "            if env.current_step == env.end_step or done:\n",
        "                average_net_worth.append(env.balance)\n",
        "                #list_of_orders.append(env.orders_history)\n",
        "                list_of_rewards.append(rewards)\n",
        "                rewards=0\n",
        "                list_of_time.append(time.time()-start_time)\n",
        "                #print(\"net_worth:\", env.net_worth)\n",
        "                break\n",
        "    print(\"AVG_time_per_episode:\", mean(list_of_time))\n",
        "    print(\"MAX_time_per_episode:\", max(list_of_time))\n",
        "    print(\"MIN_time_per_episode:\", min(list_of_time))\n",
        "    print(\"average_net_worth:\", sum(average_net_worth)/train_episodes)\n",
        "    print(\"results above initial:\", sum(i > env.initial_balance for i in average_net_worth))\n",
        "    print(\"best_net_worth:\", max(average_net_worth))\n",
        "    #print('best env: '+str(list_of_orders[average_net_worth.index(max(average_net_worth))]))\n",
        "    print(f'Indeks najlepszego: {average_net_worth.index(max(average_net_worth))}')\n",
        "    cv = lambda x: abs(stdev(x) / mean(x)) * 100 \n",
        "    print('mediana: ', end='  ')\n",
        "    print(median(list_of_rewards), end='  ')\n",
        "    print('srednia: ', end=' ')\n",
        "    print(mean(list_of_rewards), end='  ')\n",
        "    print('wsp. zmiennosci: ', end='  ')\n",
        "    print(cv(list_of_rewards), end='%  ')\n",
        "    return list_of_rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3J-H0tymiqv"
      },
      "outputs": [],
      "source": [
        "train_env = CustomEnv(df, lookback_window_size=5, max_steps=18_000, visualize=True, initial_balance=20, init_postition_size=2.0, leverage=125)\n",
        "najlpeszy = Random_games(train_env, visualize=False, train_episodes=10, training_batch_size=18_000)\n",
        "#mean(najlpeszy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RLtrader2_5.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}